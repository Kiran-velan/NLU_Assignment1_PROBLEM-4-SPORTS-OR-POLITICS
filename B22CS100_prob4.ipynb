{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0goc0X_zLlXx"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QpoMxXz2KYXK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZzxW-TCLsw-"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qI6hehQLgzU",
        "outputId": "0138ca0d-905b-472e-8c54-ddc5a40a1bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0  Budget to set scene for election\\n \\n Gordon B...      0\n",
            "1  Army chiefs in regiments decision\\n \\n Militar...      0\n",
            "2  Howard denies split over ID cards\\n \\n Michael...      0\n",
            "3  Observers to monitor UK election\\n \\n Minister...      0\n",
            "4  Kilroy names election seat target\\n \\n Ex-chat...      0\n",
            "label\n",
            "1    511\n",
            "0    417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"pol_spo.csv\")\n",
        "\n",
        "print(df.head())\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRykJNBuMNKW"
      },
      "source": [
        "Basic text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zPp86neYLv_S"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)  # remove punctuation & numbers\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "X = df['clean_text']\n",
        "y = df['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySRu25WXMRns"
      },
      "source": [
        "Train-Test split (70-30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK2VNkVKMPIS",
        "outputId": "6bade012-e82e-4e9a-d698-c88759ec9f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 649\n",
            "Test size: 279\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "# Removes any ordering bias from the dataset and ensures that the class distribution is maintained in both training and testing sets.\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Test size:\", len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCf8puJEMVI_"
      },
      "source": [
        "Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDcqBZvMYJ-"
      },
      "source": [
        "A) Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjDTpSW3MTM6"
      },
      "outputs": [],
      "source": [
        "bow_vectorizer = CountVectorizer(stop_words='english', max_features=5000) # max vocabulary size to limit features\n",
        "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
        "X_test_bow = bow_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-SYxnApMdis"
      },
      "source": [
        "B) TF-IDF (unigrams + bigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwIgv-CQMbhx"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=5000) # max vocabulary size and uni- + bi-grams\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_GPdKDOMhwo"
      },
      "source": [
        "Train & Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EpP1tqakMfji"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, X_train_vec, X_test_vec, y_train, y_test, model_name):\n",
        "    model.fit(X_train_vec, y_train)\n",
        "    y_pred = model.predict(X_test_vec)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\n===== {model_name} =====\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"Politics\", \"Sports\"]))\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab9fzOj4MmgK"
      },
      "source": [
        "Model 1 — Naive Bayes (BoW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdvrgusAMk1L",
        "outputId": "dc9d131b-7f27-47ce-9100-74b7cab32005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Naive Bayes (BoW) =====\n",
            "Accuracy: 0.996415770609319\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Politics       0.99      1.00      1.00       125\n",
            "      Sports       1.00      0.99      1.00       154\n",
            "\n",
            "    accuracy                           1.00       279\n",
            "   macro avg       1.00      1.00      1.00       279\n",
            "weighted avg       1.00      1.00      1.00       279\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb = MultinomialNB()\n",
        "acc_nb_bow = train_and_evaluate(nb, X_train_bow, X_test_bow, y_train, y_test, \"Naive Bayes (BoW)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZYFClvHMpnE"
      },
      "source": [
        "Model 2 — Logistic Regression (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW-dyJvrMoQ6",
        "outputId": "ac64f4d5-b4e2-477f-adbc-bb22a1d5f85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Logistic Regression (TF-IDF) =====\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Politics       1.00      1.00      1.00       125\n",
            "      Sports       1.00      1.00      1.00       154\n",
            "\n",
            "    accuracy                           1.00       279\n",
            "   macro avg       1.00      1.00      1.00       279\n",
            "weighted avg       1.00      1.00      1.00       279\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression(max_iter=1000)\n",
        "acc_lr_tfidf = train_and_evaluate(lr, X_train_tfidf, X_test_tfidf, y_train, y_test, \"Logistic Regression (TF-IDF)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH62x_8oMtBr"
      },
      "source": [
        "Model 3 — SVM (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZD9avFGMrVK",
        "outputId": "90bac63a-eba8-4de1-bcad-6729e97edc73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== SVM (TF-IDF) =====\n",
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Politics       1.00      1.00      1.00       125\n",
            "      Sports       1.00      1.00      1.00       154\n",
            "\n",
            "    accuracy                           1.00       279\n",
            "   macro avg       1.00      1.00      1.00       279\n",
            "weighted avg       1.00      1.00      1.00       279\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm = LinearSVC()\n",
        "acc_svm_tfidf = train_and_evaluate(svm, X_train_tfidf, X_test_tfidf, y_train, y_test, \"SVM (TF-IDF)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILG34OqKMxLG"
      },
      "source": [
        "Compare results in a table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "2bU84d2IMvO6",
        "outputId": "fed03f62-96f0-4966-df70-d01d2652f5cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive Bayes (BoW)</td>\n",
              "      <td>0.996416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression (TF-IDF)</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM (TF-IDF)</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Model  Accuracy\n",
              "0             Naive Bayes (BoW)  0.996416\n",
              "1  Logistic Regression (TF-IDF)  1.000000\n",
              "2                  SVM (TF-IDF)  1.000000"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"Naive Bayes (BoW)\", \"Logistic Regression (TF-IDF)\", \"SVM (TF-IDF)\"],\n",
        "    \"Accuracy\": [acc_nb_bow, acc_lr_tfidf, acc_svm_tfidf]\n",
        "})\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "End"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
